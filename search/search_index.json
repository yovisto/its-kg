{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ITsJOINTLY / WLO Knowledge Graph Willkommen beim WLO Knowledge Graph (WLOKG). Was ist der WLO Knowledge Graph Der WLO Knowledge Graph ist ein RDF/OWL-basierter Wissensgraph f\u00fcr die Open Educational Resource (OER)-Plattform Wir Lenen Online (WLO) . Der Wissengraph wurde im Rahmen des ITsJOINTLY Projektes entwickelt. Er dient dazu, Bildungsinhalte f\u00fcr Schulen strukturiert, vernetzt und maschineninterpretierbar bereitzustellen. Ziel ist es, die Nutzung und das Wiederauffinden von hochwertigen, offenen Lernmaterialien f\u00fcr Lehrende und Lernende zu erleichtern. Dieser Einf\u00fchrungstext gibt eine \u00dcbersicht \u00fcber den Aufbau und die Funktionsweise des Wissensgraphen sowie \u00fcber die verwendeten Kernkonzepte des Semantic Web, die ihn erm\u00f6glichen. Die Nutzung eines Wissensgraphen zur Organisation der WLO-Inhalte bietet verschiedene Vorteile: Interoperabilit\u00e4t und Austauschbarkeit: Durch die Verwendung offener Standards wie RDF und OWL ist der Wissensgraph interoperabel und kann leicht mit anderen Systemen und Datenquellen (z.B. Wikidata, DBpedia, Normdaten, etc.) verkn\u00fcpft werden. Skalierbarkeit und Erweiterbarkeit: Neue Themen, F\u00e4cher oder Inhalte lassen sich leicht in das vorhandene Wissensnetz einf\u00fcgen. Automatisierung und Empfehlungen: Die Plattform kann auf Basis der Wissensgraphen-Struktur automatisierte Empfehlungen anbieten, die \u00fcber eine traditionelle Suchfunktion hinausgehen, z.B. thematisch relevante Inhalte. Verbesserte Suchbarkeit und Kontextualisierung: Durch die semantische Verkn\u00fcpfung von Begriffen und Konzepten k\u00f6nnen Benutzer in angeschlossenen Systemen schneller relevante Informationen finden, die durch ihre Bedeutung und nicht nur durch Schl\u00fcsselw\u00f6rter definiert sind. Transparenz und Nachvollziehbarkeit: Der Wissensgraph erm\u00f6glicht eine nachvollziehbare Darstellung von Verbindungen, Quellen und Empfehlungen, was die Transparenz und das Vertrauen in die bereitgestellten Inhalte erh\u00f6ht. Multidimensionale Analyse: Der Wissensgraph erlaubt eine vielschichtige Analyse von Inhalten, sodass Trends, Wissensl\u00fccken und Zusammenh\u00e4nge auf verschiedenen Ebenen untersucht werden k\u00f6nnen. Integration von maschinellem Lernen und KI: Der Wissensgraph bildet eine ideale Grundlage f\u00fcr den Einsatz von KI-Algorithmen, die neue Erkenntnisse aus bestehenden Daten ableiten oder verborgene Zusammenh\u00e4nge entdecken k\u00f6nnen. Es gibt zahlreiche Anwendungsszenarien, auf die wir im Verlauf dieses Dokuments eingehen werden. Kernkonzepte: RDF, OWL und SPARQL Die wichtigsten Technologien, die bei der Erzeugung und Verwendung des WLO Wissensgraphen zum Einsatz kommen sind RDF, OWL und SPARQL. RDF \u2013 Die Basisstruktur des Wissensgraphen RDF (Resource Description Framework) bildet das Fundament des Wissensgraphen. In RDF wird Wissen in Form von sogenannten Tripeln gespeichert, die jeweils aus einem Subjekt, einem Pr\u00e4dikat und einem Objekt bestehen. Ein Beispiel f\u00fcr ein RDF-Tripel in unserem Wissensgraphen k\u00f6nnte sein: \u201eLernressource A hat Thema \u201aMathematik\u2018\u201c. Solche Tripel erm\u00f6glichen es, Informationen einfach zu verkn\u00fcpfen und dadurch Wissensnetze zu schaffen. Jeder Teil eines Tripels ist dabei durch einen IRI (International Resource Identifier) eindeutig gekennzeichnet, was Verwechslungen ausschlie\u00dft und Interoperabilit\u00e4t zwischen verschiedenen Systemen unterst\u00fctzt. Mehr Details zu RDF k\u00f6nnen in der RDF-Spezifikation gefunden werden. OWL \u2013 Ontologien zur Definition von Beziehungen OWL (Web Ontology Language) baut auf RDF auf und erlaubt es, komplexe Beziehungen und Hierarchien zwischen den verschiedenen Bildungsinhalten festzulegen. Eine Ontologie definiert dabei das Vokabular und die Regeln, mit denen die Bildungsressourcen beschrieben und miteinander in Beziehung gesetzt werden k\u00f6nnen. Beispielsweise k\u00f6nnte in einer OWL-Ontologie definiert sein, dass eine \"Lernressource\" entweder eine \"Aufgabe\" oder ein \"Lehrplan-Dokument\" sein kann und dass jedes Lehrplan-Dokument einem bestimmten Bildungsziel zugeordnet ist. Durch diese semantische Struktur lassen sich Zusammenh\u00e4nge zwischen verschiedenen Ressourcen und Bildungsstufen logisch abbilden und gezielt f\u00fcr die Suche und Empfehlung nutzen. Die komplette Spezifikation von OWL kann hier gefunden werden: OWL 2 Web Ontology Language SPARQL \u2013 Abfragen von Informationen SPARQL ist die Abfragesprache f\u00fcr RDF-basierte Wissensgraphen. Sie erm\u00f6glicht es, spezifische Informationen oder Beziehungen im WLO Wissensgraphen abzurufen, etwa alle verf\u00fcgbaren Mathematik-Ressourcen f\u00fcr die Sekundarstufe I. Dadurch wird der Wissensgraph durchsuchbar und Nutzer k\u00f6nnen gezielt Bildungsinhalte finden, die ihren Lernbed\u00fcrfnissen entsprechen. Die genaue Syntax und eine Beschreibung ihrer Funktionen kann unter SPARQL Abfragesprache gefunden werden. RDF, OWL und SPARQL sind komplexe Technologien mit vielen M\u00f6glichkeiten. Eine \u00fcbersichtliche Einf\u00fchrung als frei verf\u00fcgbare Videos gibt die Vorlesung \" Knowledge Graphs - Foundations and Applications \". Weitere spannende Resourcen, Links und Tutorials k\u00f6nnen unter Awesome Semantic Web gefunden werden. Wie wird der WLO Knowledge Graph erzeugt Der WLO Knowledge Graph wird aus Metadaten der Inhalte der WLO Plattform automatisch generiert. Das Update erfolgt in regelm\u00e4\u00dfigen Abst\u00e4nden (aktuell einmal w\u00f6chentlich). Zus\u00e4tzlich werden auch andere Ressourcen in den Wissensgraphen importiert. Hierzu z\u00e4hlen zum Beispiel relevante Teile aus Wikidata, verschiedene kontrollierte Vokabulare, zum Beispiel aus dem Repository der DINI AG KIM , GND , Wordnet , Kompetenz Frameworks (z.B. ESCO), Lehrplandaten oder Sachgebietssystematiken. Die im WLO Knowledge Graph zusammengestellten Daten k\u00f6nnen anschlie\u00dfend durch verschiedene Anwendungen abgefragt und verwendet werden. Hierzu z\u00e4hlen unter anderem Empfehlungssysteme, semantische Suche oder Lernpfade. Wie ist der Wissengraph aufgebaut? Zun\u00e4chst ein kleiner Ausflug in die Welt von RDF. Gem\u00e4\u00df RDF Standard werden alle \"Dinge\" durch einen International Resource Identifier (IRI) repr\u00e4sentiert. So steht z.B. der IRI https://dbpedia.org/resource/Albert_Einstein F\u00fcr den ber\u00fchmten Wissenschaftler \"Albert Einstein\". Der IRI ist also ein Symbol f\u00fcr das Konzept, das in unseren K\u00f6pfen entsteht, wenn wir z.B. \u00fcber diese bestimmte Person sprechen. Der IRI repr\u00e4sentiert also diese Person. Warum verwenden wir nicht einfach den Namen? Die nat\u00fcrliche Sprache ist mehrdeutig, d.h. es gibt \"Dinge\" die denselben Namen haben, aber unterschiedliche Bedeutung (sogenannte Polyseme), z.B. Bank. Erst durch die Verwendung des Begriffes, insbesondere mit welchen anderen Begriffen er verwendet wird (den Kontext), wird klar, welche Bedeutung gemeint ist. Z.B. \"die Bank zum Sitzen\", \"die Bank als Geldinstitut\", \"die Sandbank\". Um auf jeder dieser Bedeutungen klar Bezug nehmen zu k\u00f6nnen, wird jede dieser Bedeutungen durch einen IRI repr\u00e4sentiert. So bedarf es keinen Kontext mehr, um die Bedeutung zu erkennen. Diese IRIs k\u00f6nnen dann in Form eines Tripels einen konkreten Fakt ausdr\u00fccken. Z.B: <https://dbpedia.org/resource/Albert_Einstein> <http://dbpedia.org/ontology/birthPlace> <http://dbpedia.org/resource/Ulm> . In diesem Beispiel aus der DBpedia wird ausgedr\u00fcckt, dass Albert Einstein in Ulm geboren wurde. Die drei Elemente werden \u00fcblicherweise als Subjekt Pr\u00e4dikat und Objekt bezeichnet. Eben genau wie ein einfacher Satz. Typischerweise werdend die IRIs in spitze Klammern \"<\" \">\" geschrieben und das Tripel mit einem Punkt \".\" beendet. Danach kann ein neues Tripel beginnen. Die genaue Bedeutung des Pr\u00e4dikats \"birthPlace\" wird in einer Ontologie beschrieben. In diesem Fall ist es die DBpedia Ontologie. Es ist \u00fcblich, dass die IRIs im Browser aufgerufen werden k\u00f6nnen. Dort ist dann weitere Information verf\u00fcgbar, wie eben z.B. die ontologische Beschreibung dessen, was der IRI repr\u00e4sentiert, z.B.: http://dbpedia.org/ontology/birthPlace Nicht immer sind die IRIs wie im obigen Beispiel \"lesbar\". Manchmal enthalten sie nur eine ID und die eigentliche Bedeutung muss dann erst nachgeschlagen werden, z.B.: http://purl.obolibrary.org/obo/GSSO_000004 . Unter anderem aus diesem Grund k\u00f6nnen auch sogenannte Literale als Objekt verwendet werden. Literale enthalten einfache Daten, die in Form der \u00fcblichen Datentypen (z.B. String, Integer, etc.) hinterlegt werden. Das kann z.B. die Beschreibung oder ein Titel dessen sein, wof\u00fcr der IRI steht. Folgende Tripel zeigen ein Beispiel: <http://purl.obolibrary.org/obo/IAO_0000115> <http://www.w3.org/2000/01/rdf-schema#label> \"definition\" . <http://purl.obolibrary.org/obo/GSSO_000004> <http://purl.obolibrary.org/obo/IAO_0000115> \"The anniversary of the day on which someone is born.\" . IAO_0000115 hat eine Bezeichnung (label) \"definition\" und GSSO_000004 hat ein \"IAO_0000115\", das lautet \"The anniversary of the day on which someone is born.\" . Mit anderen Worten: GSSO_000004 hat die Definition \"The anniversary of the day on which someone is born.\" . Das wirkt alles etwas umst\u00e4ndlich, aber diese Darstellung erm\u00f6glicht es, sehr komplexe Wissenstrukturen logisch auszudr\u00fccken, sodass Maschinen bzw. Computerprogramme diese Daten sehr gut verarbeiten k\u00f6nnen. Im Beispiel ist auch zu sehen, dass die Bedeutung der einzelnen IRIs auch wieder durch Tripel beschrieben werden kann. Das erinnert irgendwie an ein \"rekursives\", sich wiederholendes System. Doch wo beginnt alles? Die Basis ist eben genau durch den RDF Standard vorgegeben. Dort ist festgelegt, das z.B. der IRI http://www.w3.org/2000/01/rdf-schema#label bedeutet, dass das Literal als Objekt den Titel dessen enth\u00e4lt, was das Subjekt repr\u00e4sentiert. Es gibt nat\u00fcrlich noch zahlreiche weitere vorgegebene Bedeutungen die im RDF Standard nachgelesen werden k\u00f6nnen. Mit RDF k\u00f6nnen sehr komplexe Zusammenh\u00e4nge dargestellt werden. Das besondere ist, dass die Art und Weise der Darstellung der Zusammenh\u00e4nge einer gewissen Logik unterliegen. Deshalb k\u00f6nnen unter bestimmten Voraussetzungen auch Schlussfolgerungen aus den Daten gezogen werden. Dennoch gibt es Grenzen. RDF hat diesbez\u00fcglich nur beschr\u00e4nkte M\u00f6glichkeiten. So k\u00f6nnen z.B. keine Inkonsistenzen festgestellt werden. Hier kommt OWL in Spiel. Mit OWL lassen sich genauere und logisch fundiertere Zusammenh\u00e4nge beschreiben. Aber dies im Detail zu erkl\u00e4ren f\u00fchrt an dieser Stelle zu weit. Nun zur\u00fcck zu WLO: Mit dem folgenden IRI wird im WLO Knowledge Graphen ein bestimmtes Dokument aus der WLO Plattform repr\u00e4sentiert: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e Klickt man darauf, erh\u00e4lt man die Informationen, die zu diesem Objekt im Knowledge Graphen bekannt sind. Oben steht das Subjekt und dann kommen die mit dem Subjekt verbundenen Pr\u00e4dikate (links) und den Objekten (rechts). Zur Darstellung dieser Webseite wird hier eine Software namens LodView verwendet. Die eigentlichen RDF Daten befinden sich in einem Triplestore. Dies ist einen spezielle Datenbank, die optimiert ist, RDF Tripel zu verarbeiten. Konkret wird hier der Virtuoso Triplestore von OpenLink in der OpenSource Variante eingesetzt. LodView ist also eine Anwendung zur Visualiserung der RDF Daten, die an den Triplestore angeschlossen ist. Um nur die konreten Tripel zum obigen IRI zu erhalten kann der Paramter \"?output=text%2Fplain\" an den IRI engeh\u00e4ngt werden: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e?output=text%2Fplain LodView liefert dann die Tripel entsprechend als Textdatei zur\u00fcck. Diese ist allerdings nicht so gut lesbar, wie die Darstellung in Lodview, dennoch kann diese Textdatei von Programmen, die RDF unterst\u00fctzen, weiter verarbeitet werden. LodView kann die Daten also \"menschenlesbar\" in Form einer Webseite oder \"maschineninterpretierbar\" in Form einer Textdatei mit Tripeln ausliefern. Doch wie kommt LodView eigentlich an die Daten im Tripelstore ran? So ziemlich jeder RDF Tripelstore bietet eine SPARQL Schnittstelle an, mit der die Daten abgerufen werden k\u00f6nnen. SPARQL steht f\u00fcr \"SPARQL Protocol And RDF Query Language\". Es ist eine formale Abfragesprache mit der Anfragen an den Triplestore gestellt werden k\u00f6nnen, der dann entsprechend mit Daten antwortet. Ein Beispiel: SELECT ?l WHERE { <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/description> ?l . } Hierbei steht ?l f\u00fcr eine freie Variable, f\u00fcr die im Triplestore konkrete Werte gesucht werden. Die freie Variable kann also anstelle eines IRIs verwendet werden. Die Anfrage lautet also: gibt alle Objekte (?l) der Tripel zur\u00fcck, deren Subjekt https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e und Pr\u00e4dikat https://schema.org/description ist. Die Anfrage kann im sogenannten SPARQL Endpoint des Triplestores eingegeben werden. F\u00fcr den hier eingesetzten Virtuoso ist das https://edu.yovisto.com/sparql . Dort kann diese Anfrage also eingegeben und abgesendet werden. Mit \"Results Format\" kann das entsprechende Format der Antwort ausgew\u00e4hlt werden (z.B. HTML f\u00fcr die Darstellung im Browser, oder CSV zum Download als Textdatei.). Zur\u00fcck zu LodView. Die LodView Web-Applikation erzeugt also aus dem IRI der im Browser aufgerufen wurde eine Anfrage an den SPARQL-Endpoint des Triplestores, erh\u00e4lt die RDF Daten als Antwort zur\u00fcck und generiert daraus entweder die Webseite oder die Textdatei mit den Tripeln. Nat\u00fcrlich k\u00f6nnen auch andere Apps auf den SPARQL-Endpoint zugreifen. Z.B. sind im folgenden Yasgui-Widget ein paar Beispielanfragen vorbereitet, die an den SPARQL-Endpoint gesendet werden k\u00f6nnen (Klick auf den dicken Pfeil). YasGUI ist ein Javascript-basierter SPARQL Editor. Los geht's mit SPARQL Zeige die ersten 15 Dokumente und ihren Titel: Zeige 15 Dokumente in deren Titel oder Beschreibungen der Begriff \"bismarck\" vorkommt: Struktur der Daten Um zu verstehen, welche Abfragen im Tripelstore m\u00f6glich sind, ist es essenziell, genau zu wissen, welche Pr\u00e4dikate verwendet werden und welche Objekte sowie Subjekte abgefragt werden k\u00f6nnen. Mit anderen Worten: Man muss die \u201eOntologie\u201c und damit die Struktur der Daten im Tripelstore kennen. Daf\u00fcr gibt es verschiedene Ans\u00e4tze. Entweder konsultiert man die vorhandene Dokumentation oder man versucht, die Struktur direkt aus den Daten abzuleiten. Beispielsweise k\u00f6nnte man zun\u00e4chst alle Pr\u00e4dikate auflisten lassen. Im n\u00e4chsten Schritt k\u00f6nnte man untersuchen, welche Subjekte ein bestimmtes Pr\u00e4dikat verwenden, und so weiter, bis man gen\u00fcgend Informationen hat, um sinnvolle Abfragen zu formulieren. Idealerweise sind die Daten jedoch umfassend dokumentiert, um diesen Prozess zu erleichtern. Mit Hilfe von Visualisierung-Tools wie LodView kann die Struktur der Daten relativ leicht erlernt werden. Schauen wir nochmal etwas genauer auf die Struktur der Ressource in LodView: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e Der Titel der Ressource lautet \"Satz des Pythagoras\". Lodview zeigt den Titel gut lesbar oben an. Die eigentliche Information steckt im Tripel: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/name> \"Satz des Pythagoras\" . Dieses Tripel wird in LodView etwas weiter unten angezeigt. Um den Titel anzugeben wird also das Pr\u00e4dikat \"https://schema.org/name\" verwendet. Auf \u00e4hnliche Weise werden auch die folgenden Informationen anhand der Pr\u00e4dikate angezeigt: https://schema.org/ description : Beschreibung der Ressource https://schema.org/ keywords : freie Schl\u00fcsselw\u00f6rter https://schema.org/ identifier : der WLO Identifikator (edusharing Plattform) https://schema.org/ license : die Lizenz der Ressource https://schema.org/ url : der URL der Quelle er Ressource http://edu.yovisto.com/ontology/1.0/ dateCreated : Zeitpunkt an dem die Ressource in WLO angelegt wurde http://edu.yovisto.com/ontology/1.0/ dateModified : Zeitpunkt er letzen \u00c4nderung bei WLO http://www.w3.org/1999/02/22-rdf-syntax-ns# type : Typ der Ressource http://www.w3.org/2000/01/rdf-schema# isDefinedBy : Named Graph, in dem die Ressource im Triplestore gespeichert ist http://xmlns.com/foaf/0.1/ depiction : verweist auf ein Bild (dies wird von Lodview oben angezeigt) https://schema.org/ audience : verweist auf eine Liste von Nutzer Rollen, f\u00fcr die die Ressource geeignet ist (z.B. f\u00fcr Sch\u00fcler und/oder Lehrer) https://schema.org/ about : zeigt auf eine Liste von Schulf\u00e4chern http://w3id.org/openeduhub/terms/ educationalContext : zeigt auf eine Liste von Schulstufen http://w3id.org/openeduhub/terms/ widget : zeigt auf eine Liste von m\u00f6glichen Darstellungstemplates der WLO Plattform https://w3id.org/curriculum/ hasAnnotationTarget : verweist auf semantische Textannotationen (dazu sp\u00e4ter mehr) In LodView werden einige Pr\u00e4dikate zur besseren \u00dcbersichtlichkeit mithilfe von Pr\u00e4fixen abgek\u00fcrzt. Ein Beispiel hierf\u00fcr ist die Abk\u00fcrzung des Pr\u00e4dikats http://www.w3.org/1999/02/22-rdf-syntax-ns#type , das in der Pr\u00e4fixschreibweise als rdf:type dargestellt wird. Diese Schreibweise macht die Darstellung von Pr\u00e4dikaten kompakter und leichter lesbar, insbesondere bei langen URIs. Das K\u00fcrzel eines Pr\u00e4fixes, wie beispielsweise rdf: in diesem Fall, kann prinzipiell frei gew\u00e4hlt werden, solange es innerhalb des jeweiligen Kontextes eindeutig bleibt. Dennoch gibt es f\u00fcr einige Pr\u00e4fixe etablierte Konventionen, die in der Praxis weitgehend einheitlich verwendet werden. Beispiele f\u00fcr solche standardisierten Pr\u00e4fixe sind rdf (f\u00fcr das RDF-Vokabular), rdfs (f\u00fcr das RDF Schema), owl (f\u00fcr die Web Ontology Language) und foaf (f\u00fcr das \u201eFriend of a Friend\u201c-Vokabular). Diese Konventionen erleichtern die Arbeit, da sie f\u00fcr Entwickler und Nutzer direkt nachvollziehbar sind und einen einheitlichen Standard gew\u00e4hrleisten. Die Pr\u00e4fixschreibweise tr\u00e4gt somit nicht nur zur \u00dcbersichtlichkeit bei, sondern erleichtert auch die Zusammenarbeit und das Verst\u00e4ndnis in Projekten, die auf RDF-Daten und Ontologien basieren. Da wir nun die Struktur eines Dokuments kennen, k\u00f6nnen wir ein paar weitere komplexere Abfragen machen: Zeige 10 Dokumente des Fach Mathematik: Es ist nat\u00fcrlich hilfreich, wenn vorab bekannt ist, dass der IRI http://w3id.org/openeduhub/vocabs/discipline/380 das Schulfach Mathematik repr\u00e4sentiert. Um alle Schulf\u00e4cher herauszufinden, k\u00f6nnte z.B. folgende Anfrage ausgef\u00fchrt werden. Zeige alle Schulf\u00e4cher, die verwendet werden: Wie viele Dokumente gibt es im Fach Mathematik: Zusammenfassung Der WLO Knowledge Graph enth\u00e4lt die \u00f6ffentlichen Metadaten der Bildungsinhalte der Wirlernenonline Plattform. Diese sind in RDF gespeichert und \u00fcber einen SPARQL Endpoint abrufbar. In diesem Abschnitt wurde RDF und die Struktur der Daten auf einem recht groben Niveau eingef\u00fchrt. F\u00fcr detaillierte Informationen wird auf die entprechenden Standards und Dokumentationen verwiesen. In n\u00e4chsten Abschnitt werden Verfahren zur semantischen Analyse der Bildungsinhalte erl\u00e4utert. Sie sind die Grundlage f\u00fcr intelligente Vernetzung der Inhalte untereinander und mit anderen externen Inhalten.","title":"Home"},{"location":"#itsjointly-wlo-knowledge-graph","text":"Willkommen beim WLO Knowledge Graph (WLOKG).","title":"ITsJOINTLY / WLO Knowledge Graph"},{"location":"#was-ist-der-wlo-knowledge-graph","text":"Der WLO Knowledge Graph ist ein RDF/OWL-basierter Wissensgraph f\u00fcr die Open Educational Resource (OER)-Plattform Wir Lenen Online (WLO) . Der Wissengraph wurde im Rahmen des ITsJOINTLY Projektes entwickelt. Er dient dazu, Bildungsinhalte f\u00fcr Schulen strukturiert, vernetzt und maschineninterpretierbar bereitzustellen. Ziel ist es, die Nutzung und das Wiederauffinden von hochwertigen, offenen Lernmaterialien f\u00fcr Lehrende und Lernende zu erleichtern. Dieser Einf\u00fchrungstext gibt eine \u00dcbersicht \u00fcber den Aufbau und die Funktionsweise des Wissensgraphen sowie \u00fcber die verwendeten Kernkonzepte des Semantic Web, die ihn erm\u00f6glichen. Die Nutzung eines Wissensgraphen zur Organisation der WLO-Inhalte bietet verschiedene Vorteile: Interoperabilit\u00e4t und Austauschbarkeit: Durch die Verwendung offener Standards wie RDF und OWL ist der Wissensgraph interoperabel und kann leicht mit anderen Systemen und Datenquellen (z.B. Wikidata, DBpedia, Normdaten, etc.) verkn\u00fcpft werden. Skalierbarkeit und Erweiterbarkeit: Neue Themen, F\u00e4cher oder Inhalte lassen sich leicht in das vorhandene Wissensnetz einf\u00fcgen. Automatisierung und Empfehlungen: Die Plattform kann auf Basis der Wissensgraphen-Struktur automatisierte Empfehlungen anbieten, die \u00fcber eine traditionelle Suchfunktion hinausgehen, z.B. thematisch relevante Inhalte. Verbesserte Suchbarkeit und Kontextualisierung: Durch die semantische Verkn\u00fcpfung von Begriffen und Konzepten k\u00f6nnen Benutzer in angeschlossenen Systemen schneller relevante Informationen finden, die durch ihre Bedeutung und nicht nur durch Schl\u00fcsselw\u00f6rter definiert sind. Transparenz und Nachvollziehbarkeit: Der Wissensgraph erm\u00f6glicht eine nachvollziehbare Darstellung von Verbindungen, Quellen und Empfehlungen, was die Transparenz und das Vertrauen in die bereitgestellten Inhalte erh\u00f6ht. Multidimensionale Analyse: Der Wissensgraph erlaubt eine vielschichtige Analyse von Inhalten, sodass Trends, Wissensl\u00fccken und Zusammenh\u00e4nge auf verschiedenen Ebenen untersucht werden k\u00f6nnen. Integration von maschinellem Lernen und KI: Der Wissensgraph bildet eine ideale Grundlage f\u00fcr den Einsatz von KI-Algorithmen, die neue Erkenntnisse aus bestehenden Daten ableiten oder verborgene Zusammenh\u00e4nge entdecken k\u00f6nnen. Es gibt zahlreiche Anwendungsszenarien, auf die wir im Verlauf dieses Dokuments eingehen werden.","title":"Was ist der WLO Knowledge Graph"},{"location":"#kernkonzepte-rdf-owl-und-sparql","text":"Die wichtigsten Technologien, die bei der Erzeugung und Verwendung des WLO Wissensgraphen zum Einsatz kommen sind RDF, OWL und SPARQL.","title":"Kernkonzepte: RDF, OWL und SPARQL"},{"location":"#rdf-die-basisstruktur-des-wissensgraphen","text":"RDF (Resource Description Framework) bildet das Fundament des Wissensgraphen. In RDF wird Wissen in Form von sogenannten Tripeln gespeichert, die jeweils aus einem Subjekt, einem Pr\u00e4dikat und einem Objekt bestehen. Ein Beispiel f\u00fcr ein RDF-Tripel in unserem Wissensgraphen k\u00f6nnte sein: \u201eLernressource A hat Thema \u201aMathematik\u2018\u201c. Solche Tripel erm\u00f6glichen es, Informationen einfach zu verkn\u00fcpfen und dadurch Wissensnetze zu schaffen. Jeder Teil eines Tripels ist dabei durch einen IRI (International Resource Identifier) eindeutig gekennzeichnet, was Verwechslungen ausschlie\u00dft und Interoperabilit\u00e4t zwischen verschiedenen Systemen unterst\u00fctzt. Mehr Details zu RDF k\u00f6nnen in der RDF-Spezifikation gefunden werden.","title":"RDF \u2013 Die Basisstruktur des Wissensgraphen"},{"location":"#owl-ontologien-zur-definition-von-beziehungen","text":"OWL (Web Ontology Language) baut auf RDF auf und erlaubt es, komplexe Beziehungen und Hierarchien zwischen den verschiedenen Bildungsinhalten festzulegen. Eine Ontologie definiert dabei das Vokabular und die Regeln, mit denen die Bildungsressourcen beschrieben und miteinander in Beziehung gesetzt werden k\u00f6nnen. Beispielsweise k\u00f6nnte in einer OWL-Ontologie definiert sein, dass eine \"Lernressource\" entweder eine \"Aufgabe\" oder ein \"Lehrplan-Dokument\" sein kann und dass jedes Lehrplan-Dokument einem bestimmten Bildungsziel zugeordnet ist. Durch diese semantische Struktur lassen sich Zusammenh\u00e4nge zwischen verschiedenen Ressourcen und Bildungsstufen logisch abbilden und gezielt f\u00fcr die Suche und Empfehlung nutzen. Die komplette Spezifikation von OWL kann hier gefunden werden: OWL 2 Web Ontology Language","title":"OWL \u2013 Ontologien zur Definition von Beziehungen"},{"location":"#sparql-abfragen-von-informationen","text":"SPARQL ist die Abfragesprache f\u00fcr RDF-basierte Wissensgraphen. Sie erm\u00f6glicht es, spezifische Informationen oder Beziehungen im WLO Wissensgraphen abzurufen, etwa alle verf\u00fcgbaren Mathematik-Ressourcen f\u00fcr die Sekundarstufe I. Dadurch wird der Wissensgraph durchsuchbar und Nutzer k\u00f6nnen gezielt Bildungsinhalte finden, die ihren Lernbed\u00fcrfnissen entsprechen. Die genaue Syntax und eine Beschreibung ihrer Funktionen kann unter SPARQL Abfragesprache gefunden werden. RDF, OWL und SPARQL sind komplexe Technologien mit vielen M\u00f6glichkeiten. Eine \u00fcbersichtliche Einf\u00fchrung als frei verf\u00fcgbare Videos gibt die Vorlesung \" Knowledge Graphs - Foundations and Applications \". Weitere spannende Resourcen, Links und Tutorials k\u00f6nnen unter Awesome Semantic Web gefunden werden.","title":"SPARQL \u2013 Abfragen von Informationen"},{"location":"#wie-wird-der-wlo-knowledge-graph-erzeugt","text":"Der WLO Knowledge Graph wird aus Metadaten der Inhalte der WLO Plattform automatisch generiert. Das Update erfolgt in regelm\u00e4\u00dfigen Abst\u00e4nden (aktuell einmal w\u00f6chentlich). Zus\u00e4tzlich werden auch andere Ressourcen in den Wissensgraphen importiert. Hierzu z\u00e4hlen zum Beispiel relevante Teile aus Wikidata, verschiedene kontrollierte Vokabulare, zum Beispiel aus dem Repository der DINI AG KIM , GND , Wordnet , Kompetenz Frameworks (z.B. ESCO), Lehrplandaten oder Sachgebietssystematiken. Die im WLO Knowledge Graph zusammengestellten Daten k\u00f6nnen anschlie\u00dfend durch verschiedene Anwendungen abgefragt und verwendet werden. Hierzu z\u00e4hlen unter anderem Empfehlungssysteme, semantische Suche oder Lernpfade.","title":"Wie wird der WLO Knowledge Graph erzeugt"},{"location":"#wie-ist-der-wissengraph-aufgebaut","text":"Zun\u00e4chst ein kleiner Ausflug in die Welt von RDF. Gem\u00e4\u00df RDF Standard werden alle \"Dinge\" durch einen International Resource Identifier (IRI) repr\u00e4sentiert. So steht z.B. der IRI https://dbpedia.org/resource/Albert_Einstein F\u00fcr den ber\u00fchmten Wissenschaftler \"Albert Einstein\". Der IRI ist also ein Symbol f\u00fcr das Konzept, das in unseren K\u00f6pfen entsteht, wenn wir z.B. \u00fcber diese bestimmte Person sprechen. Der IRI repr\u00e4sentiert also diese Person. Warum verwenden wir nicht einfach den Namen? Die nat\u00fcrliche Sprache ist mehrdeutig, d.h. es gibt \"Dinge\" die denselben Namen haben, aber unterschiedliche Bedeutung (sogenannte Polyseme), z.B. Bank. Erst durch die Verwendung des Begriffes, insbesondere mit welchen anderen Begriffen er verwendet wird (den Kontext), wird klar, welche Bedeutung gemeint ist. Z.B. \"die Bank zum Sitzen\", \"die Bank als Geldinstitut\", \"die Sandbank\". Um auf jeder dieser Bedeutungen klar Bezug nehmen zu k\u00f6nnen, wird jede dieser Bedeutungen durch einen IRI repr\u00e4sentiert. So bedarf es keinen Kontext mehr, um die Bedeutung zu erkennen. Diese IRIs k\u00f6nnen dann in Form eines Tripels einen konkreten Fakt ausdr\u00fccken. Z.B: <https://dbpedia.org/resource/Albert_Einstein> <http://dbpedia.org/ontology/birthPlace> <http://dbpedia.org/resource/Ulm> . In diesem Beispiel aus der DBpedia wird ausgedr\u00fcckt, dass Albert Einstein in Ulm geboren wurde. Die drei Elemente werden \u00fcblicherweise als Subjekt Pr\u00e4dikat und Objekt bezeichnet. Eben genau wie ein einfacher Satz. Typischerweise werdend die IRIs in spitze Klammern \"<\" \">\" geschrieben und das Tripel mit einem Punkt \".\" beendet. Danach kann ein neues Tripel beginnen. Die genaue Bedeutung des Pr\u00e4dikats \"birthPlace\" wird in einer Ontologie beschrieben. In diesem Fall ist es die DBpedia Ontologie. Es ist \u00fcblich, dass die IRIs im Browser aufgerufen werden k\u00f6nnen. Dort ist dann weitere Information verf\u00fcgbar, wie eben z.B. die ontologische Beschreibung dessen, was der IRI repr\u00e4sentiert, z.B.: http://dbpedia.org/ontology/birthPlace Nicht immer sind die IRIs wie im obigen Beispiel \"lesbar\". Manchmal enthalten sie nur eine ID und die eigentliche Bedeutung muss dann erst nachgeschlagen werden, z.B.: http://purl.obolibrary.org/obo/GSSO_000004 . Unter anderem aus diesem Grund k\u00f6nnen auch sogenannte Literale als Objekt verwendet werden. Literale enthalten einfache Daten, die in Form der \u00fcblichen Datentypen (z.B. String, Integer, etc.) hinterlegt werden. Das kann z.B. die Beschreibung oder ein Titel dessen sein, wof\u00fcr der IRI steht. Folgende Tripel zeigen ein Beispiel: <http://purl.obolibrary.org/obo/IAO_0000115> <http://www.w3.org/2000/01/rdf-schema#label> \"definition\" . <http://purl.obolibrary.org/obo/GSSO_000004> <http://purl.obolibrary.org/obo/IAO_0000115> \"The anniversary of the day on which someone is born.\" . IAO_0000115 hat eine Bezeichnung (label) \"definition\" und GSSO_000004 hat ein \"IAO_0000115\", das lautet \"The anniversary of the day on which someone is born.\" . Mit anderen Worten: GSSO_000004 hat die Definition \"The anniversary of the day on which someone is born.\" . Das wirkt alles etwas umst\u00e4ndlich, aber diese Darstellung erm\u00f6glicht es, sehr komplexe Wissenstrukturen logisch auszudr\u00fccken, sodass Maschinen bzw. Computerprogramme diese Daten sehr gut verarbeiten k\u00f6nnen. Im Beispiel ist auch zu sehen, dass die Bedeutung der einzelnen IRIs auch wieder durch Tripel beschrieben werden kann. Das erinnert irgendwie an ein \"rekursives\", sich wiederholendes System. Doch wo beginnt alles? Die Basis ist eben genau durch den RDF Standard vorgegeben. Dort ist festgelegt, das z.B. der IRI http://www.w3.org/2000/01/rdf-schema#label bedeutet, dass das Literal als Objekt den Titel dessen enth\u00e4lt, was das Subjekt repr\u00e4sentiert. Es gibt nat\u00fcrlich noch zahlreiche weitere vorgegebene Bedeutungen die im RDF Standard nachgelesen werden k\u00f6nnen. Mit RDF k\u00f6nnen sehr komplexe Zusammenh\u00e4nge dargestellt werden. Das besondere ist, dass die Art und Weise der Darstellung der Zusammenh\u00e4nge einer gewissen Logik unterliegen. Deshalb k\u00f6nnen unter bestimmten Voraussetzungen auch Schlussfolgerungen aus den Daten gezogen werden. Dennoch gibt es Grenzen. RDF hat diesbez\u00fcglich nur beschr\u00e4nkte M\u00f6glichkeiten. So k\u00f6nnen z.B. keine Inkonsistenzen festgestellt werden. Hier kommt OWL in Spiel. Mit OWL lassen sich genauere und logisch fundiertere Zusammenh\u00e4nge beschreiben. Aber dies im Detail zu erkl\u00e4ren f\u00fchrt an dieser Stelle zu weit. Nun zur\u00fcck zu WLO: Mit dem folgenden IRI wird im WLO Knowledge Graphen ein bestimmtes Dokument aus der WLO Plattform repr\u00e4sentiert: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e Klickt man darauf, erh\u00e4lt man die Informationen, die zu diesem Objekt im Knowledge Graphen bekannt sind. Oben steht das Subjekt und dann kommen die mit dem Subjekt verbundenen Pr\u00e4dikate (links) und den Objekten (rechts). Zur Darstellung dieser Webseite wird hier eine Software namens LodView verwendet. Die eigentlichen RDF Daten befinden sich in einem Triplestore. Dies ist einen spezielle Datenbank, die optimiert ist, RDF Tripel zu verarbeiten. Konkret wird hier der Virtuoso Triplestore von OpenLink in der OpenSource Variante eingesetzt. LodView ist also eine Anwendung zur Visualiserung der RDF Daten, die an den Triplestore angeschlossen ist. Um nur die konreten Tripel zum obigen IRI zu erhalten kann der Paramter \"?output=text%2Fplain\" an den IRI engeh\u00e4ngt werden: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e?output=text%2Fplain LodView liefert dann die Tripel entsprechend als Textdatei zur\u00fcck. Diese ist allerdings nicht so gut lesbar, wie die Darstellung in Lodview, dennoch kann diese Textdatei von Programmen, die RDF unterst\u00fctzen, weiter verarbeitet werden. LodView kann die Daten also \"menschenlesbar\" in Form einer Webseite oder \"maschineninterpretierbar\" in Form einer Textdatei mit Tripeln ausliefern. Doch wie kommt LodView eigentlich an die Daten im Tripelstore ran? So ziemlich jeder RDF Tripelstore bietet eine SPARQL Schnittstelle an, mit der die Daten abgerufen werden k\u00f6nnen. SPARQL steht f\u00fcr \"SPARQL Protocol And RDF Query Language\". Es ist eine formale Abfragesprache mit der Anfragen an den Triplestore gestellt werden k\u00f6nnen, der dann entsprechend mit Daten antwortet. Ein Beispiel: SELECT ?l WHERE { <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/description> ?l . } Hierbei steht ?l f\u00fcr eine freie Variable, f\u00fcr die im Triplestore konkrete Werte gesucht werden. Die freie Variable kann also anstelle eines IRIs verwendet werden. Die Anfrage lautet also: gibt alle Objekte (?l) der Tripel zur\u00fcck, deren Subjekt https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e und Pr\u00e4dikat https://schema.org/description ist. Die Anfrage kann im sogenannten SPARQL Endpoint des Triplestores eingegeben werden. F\u00fcr den hier eingesetzten Virtuoso ist das https://edu.yovisto.com/sparql . Dort kann diese Anfrage also eingegeben und abgesendet werden. Mit \"Results Format\" kann das entsprechende Format der Antwort ausgew\u00e4hlt werden (z.B. HTML f\u00fcr die Darstellung im Browser, oder CSV zum Download als Textdatei.). Zur\u00fcck zu LodView. Die LodView Web-Applikation erzeugt also aus dem IRI der im Browser aufgerufen wurde eine Anfrage an den SPARQL-Endpoint des Triplestores, erh\u00e4lt die RDF Daten als Antwort zur\u00fcck und generiert daraus entweder die Webseite oder die Textdatei mit den Tripeln. Nat\u00fcrlich k\u00f6nnen auch andere Apps auf den SPARQL-Endpoint zugreifen. Z.B. sind im folgenden Yasgui-Widget ein paar Beispielanfragen vorbereitet, die an den SPARQL-Endpoint gesendet werden k\u00f6nnen (Klick auf den dicken Pfeil). YasGUI ist ein Javascript-basierter SPARQL Editor.","title":"Wie ist der Wissengraph aufgebaut?"},{"location":"#los-gehts-mit-sparql","text":"Zeige die ersten 15 Dokumente und ihren Titel: Zeige 15 Dokumente in deren Titel oder Beschreibungen der Begriff \"bismarck\" vorkommt:","title":"Los geht's mit SPARQL"},{"location":"#struktur-der-daten","text":"Um zu verstehen, welche Abfragen im Tripelstore m\u00f6glich sind, ist es essenziell, genau zu wissen, welche Pr\u00e4dikate verwendet werden und welche Objekte sowie Subjekte abgefragt werden k\u00f6nnen. Mit anderen Worten: Man muss die \u201eOntologie\u201c und damit die Struktur der Daten im Tripelstore kennen. Daf\u00fcr gibt es verschiedene Ans\u00e4tze. Entweder konsultiert man die vorhandene Dokumentation oder man versucht, die Struktur direkt aus den Daten abzuleiten. Beispielsweise k\u00f6nnte man zun\u00e4chst alle Pr\u00e4dikate auflisten lassen. Im n\u00e4chsten Schritt k\u00f6nnte man untersuchen, welche Subjekte ein bestimmtes Pr\u00e4dikat verwenden, und so weiter, bis man gen\u00fcgend Informationen hat, um sinnvolle Abfragen zu formulieren. Idealerweise sind die Daten jedoch umfassend dokumentiert, um diesen Prozess zu erleichtern. Mit Hilfe von Visualisierung-Tools wie LodView kann die Struktur der Daten relativ leicht erlernt werden. Schauen wir nochmal etwas genauer auf die Struktur der Ressource in LodView: https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e Der Titel der Ressource lautet \"Satz des Pythagoras\". Lodview zeigt den Titel gut lesbar oben an. Die eigentliche Information steckt im Tripel: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/name> \"Satz des Pythagoras\" . Dieses Tripel wird in LodView etwas weiter unten angezeigt. Um den Titel anzugeben wird also das Pr\u00e4dikat \"https://schema.org/name\" verwendet. Auf \u00e4hnliche Weise werden auch die folgenden Informationen anhand der Pr\u00e4dikate angezeigt: https://schema.org/ description : Beschreibung der Ressource https://schema.org/ keywords : freie Schl\u00fcsselw\u00f6rter https://schema.org/ identifier : der WLO Identifikator (edusharing Plattform) https://schema.org/ license : die Lizenz der Ressource https://schema.org/ url : der URL der Quelle er Ressource http://edu.yovisto.com/ontology/1.0/ dateCreated : Zeitpunkt an dem die Ressource in WLO angelegt wurde http://edu.yovisto.com/ontology/1.0/ dateModified : Zeitpunkt er letzen \u00c4nderung bei WLO http://www.w3.org/1999/02/22-rdf-syntax-ns# type : Typ der Ressource http://www.w3.org/2000/01/rdf-schema# isDefinedBy : Named Graph, in dem die Ressource im Triplestore gespeichert ist http://xmlns.com/foaf/0.1/ depiction : verweist auf ein Bild (dies wird von Lodview oben angezeigt) https://schema.org/ audience : verweist auf eine Liste von Nutzer Rollen, f\u00fcr die die Ressource geeignet ist (z.B. f\u00fcr Sch\u00fcler und/oder Lehrer) https://schema.org/ about : zeigt auf eine Liste von Schulf\u00e4chern http://w3id.org/openeduhub/terms/ educationalContext : zeigt auf eine Liste von Schulstufen http://w3id.org/openeduhub/terms/ widget : zeigt auf eine Liste von m\u00f6glichen Darstellungstemplates der WLO Plattform https://w3id.org/curriculum/ hasAnnotationTarget : verweist auf semantische Textannotationen (dazu sp\u00e4ter mehr) In LodView werden einige Pr\u00e4dikate zur besseren \u00dcbersichtlichkeit mithilfe von Pr\u00e4fixen abgek\u00fcrzt. Ein Beispiel hierf\u00fcr ist die Abk\u00fcrzung des Pr\u00e4dikats http://www.w3.org/1999/02/22-rdf-syntax-ns#type , das in der Pr\u00e4fixschreibweise als rdf:type dargestellt wird. Diese Schreibweise macht die Darstellung von Pr\u00e4dikaten kompakter und leichter lesbar, insbesondere bei langen URIs. Das K\u00fcrzel eines Pr\u00e4fixes, wie beispielsweise rdf: in diesem Fall, kann prinzipiell frei gew\u00e4hlt werden, solange es innerhalb des jeweiligen Kontextes eindeutig bleibt. Dennoch gibt es f\u00fcr einige Pr\u00e4fixe etablierte Konventionen, die in der Praxis weitgehend einheitlich verwendet werden. Beispiele f\u00fcr solche standardisierten Pr\u00e4fixe sind rdf (f\u00fcr das RDF-Vokabular), rdfs (f\u00fcr das RDF Schema), owl (f\u00fcr die Web Ontology Language) und foaf (f\u00fcr das \u201eFriend of a Friend\u201c-Vokabular). Diese Konventionen erleichtern die Arbeit, da sie f\u00fcr Entwickler und Nutzer direkt nachvollziehbar sind und einen einheitlichen Standard gew\u00e4hrleisten. Die Pr\u00e4fixschreibweise tr\u00e4gt somit nicht nur zur \u00dcbersichtlichkeit bei, sondern erleichtert auch die Zusammenarbeit und das Verst\u00e4ndnis in Projekten, die auf RDF-Daten und Ontologien basieren. Da wir nun die Struktur eines Dokuments kennen, k\u00f6nnen wir ein paar weitere komplexere Abfragen machen: Zeige 10 Dokumente des Fach Mathematik: Es ist nat\u00fcrlich hilfreich, wenn vorab bekannt ist, dass der IRI http://w3id.org/openeduhub/vocabs/discipline/380 das Schulfach Mathematik repr\u00e4sentiert. Um alle Schulf\u00e4cher herauszufinden, k\u00f6nnte z.B. folgende Anfrage ausgef\u00fchrt werden. Zeige alle Schulf\u00e4cher, die verwendet werden: Wie viele Dokumente gibt es im Fach Mathematik:","title":"Struktur der Daten"},{"location":"#zusammenfassung","text":"Der WLO Knowledge Graph enth\u00e4lt die \u00f6ffentlichen Metadaten der Bildungsinhalte der Wirlernenonline Plattform. Diese sind in RDF gespeichert und \u00fcber einen SPARQL Endpoint abrufbar. In diesem Abschnitt wurde RDF und die Struktur der Daten auf einem recht groben Niveau eingef\u00fchrt. F\u00fcr detaillierte Informationen wird auf die entprechenden Standards und Dokumentationen verwiesen. In n\u00e4chsten Abschnitt werden Verfahren zur semantischen Analyse der Bildungsinhalte erl\u00e4utert. Sie sind die Grundlage f\u00fcr intelligente Vernetzung der Inhalte untereinander und mit anderen externen Inhalten.","title":"Zusammenfassung"},{"location":"annotationen/","text":"Semantische Analyse in Knowledge Graphs Die semantische Analyse innerhalb von Wissensgraphen, die auf RDF (Resource Description Framework) basieren, bezieht sich auf den Prozess der Interpretation und Verarbeitung von Daten, um deren Bedeutung und Beziehungen zu verstehen. Durch die Verwendung von Ontologien und Vokabularen erm\u00f6glicht die semantische Analyse, dass Informationen nicht nur als einfache Datenpunkte, sondern als bedeutungsvolle Entit\u00e4ten und deren Verkn\u00fcpfungen betrachtet werden. Dies f\u00f6rdert die F\u00e4higkeit, komplexe Abfragen zu stellen, inferenzielle Schlussfolgerungen zu ziehen und neue Erkenntnisse aus den verkn\u00fcpften Daten zu gewinnen. In Wissensgraphen wird die semantische Analyse genutzt, um die Interoperabilit\u00e4t zwischen verschiedenen Datenquellen zu verbessern und eine tiefere Einsicht in die zugrunde liegenden Informationen zu erm\u00f6glichen. Zu diesem Zweck werden Annotationen verwendet, und wir betrachten dies in den folgenden Abschnitten n\u00e4her. Annotationen Wie bereits erw\u00e4hnt, k\u00f6nnen RDF Daten in Form von Tripeln dargestellt werden, die aus einem Subjekt, einem Pr\u00e4dikat und einem Objekt bestehen. Das Objekt kann entweder ein Literal oder eine Ressource (IRI) sein. Ein Literal ist ein konkreter Wert, wie zum Beispiel ein Text oder eine Zahl, der direkt in den Tripel eingef\u00fcgt wird, wie \"42\" oder \"Hallo Welt\". Eine Ressource hingegen verweist auf ein Konzept oder eine Entit\u00e4t, die durch eine IRI identifiziert wird, wie zum Beispiel eine Person oder einen Ort. NIF , das f\u00fcr NLP Interchange Format steht, ist eine Architektur und Methodologie zur Annotation von Literalen oder Texten innerhalb eines Wissensgraphen. Es erm\u00f6glicht die standardisierte Darstellung von Textannotationen in RDF (Resource Description Framework), wodurch die Integration von nat\u00fcrlichen Sprachverarbeitungswerkzeugen und -ressourcen erleichtert wird. Mit NIF k\u00f6nnen verschiedene Entit\u00e4ten, Konzepte und Beziehungen innerhalb von Texten annotiert werden, was die Interoperabilit\u00e4t zwischen unterschiedlichen NLP-Systemen f\u00f6rdert. Diese Flexibilit\u00e4t und die M\u00f6glichkeit, kontextuelle Informationen einzubeziehen, machen NIF zu einem wertvollen Instrument f\u00fcr die Anreicherung von Wissensgraphen mit reichhaltigen, annotierten Textdaten. Schauen wir uns noch einmal unser Triple an, das den Titel der \"Satz des Pythagoras\" Ressource darstellt: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/name> \"Satz des Pythagoras\" . Wenn wir nun mit einem weiteren Triple angeben m\u00f6chten, dass wir den Text \"Satz des Pythagoras\" (in anderen Worten das Objektliteral) in diesem Triple annotieren wollen, w\u00fcrde es wie folgt aussehen: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . Der letzte Teil der Objekt-URI im Triple (nif=context_p=name_char=0,19) dient als Kontextbeschreibung dessen, was wir annotieren. In diesem Fall annotieren wir die Eigenschaft name (https://schema.org/name), und char=0,19 zeigt an, dass wir alle Zeichen im Text als unseren Kontext spezifizieren. Nachdem wir den Annotation-Kontext definiert haben, wenden wir uns nun dem eigentlichen Annotierungsprozess zu. Der Annotierungsprozess analysiert die W\u00f6rter innerhalb des festgelegten Annotation-Kontexts. Dies geschieht durch den sogenannten 'Annotator'. Es k\u00f6nnen mehrere Annotatoren auf den Text angewendet werden, und je nach Annotator sind wir in der Lage, weitere Informationen aus dem Text zu extrahieren und diese wiederum mit anderen externen Wissensgraphen zu verkn\u00fcpfen. In unserem Fall verwenden wir zwei Annotatoren, n\u00e4mlich DBpedia Spotlight und spaCy . DBpedia Spotlight ist ein Tool zur automatischen Annotation von Texten, das es erm\u00f6glicht, Entit\u00e4ten aus der DBpedia-Wissensgraph in unstrukturierten Texten zu identifizieren und zu verlinken. DBpedia-Entit\u00e4ten k\u00f6nnen auch problemlos mit Wikidata-Entit\u00e4ten verkn\u00fcpft werden, einem weiteren wichtigen externen Wissensgraphen, der strukturierte Daten \u00fcber Personen, Orte und Dinge bereitstellt. Wenn wir unser Beispiel nun weiter ausbauen, sind wir in der Lage, mit zwei neuen Tripeln, DBpedia-Entit\u00e4ten auf folgende Weise mit dem bereits definierten Kontext zu verkn\u00fcpfen: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=dbpedia-spotlight_p=name_char=9,19> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=dbpedia-spotlight_p=name_char=9,19> <http://www.w3.org/2005/11/its/rdf#taIdentRef> <http://de.dbpedia.org/resource/Pythagoras> . Im letzten Teil des Subjekts des ersten Tripels sehen wir, dass der Annotator als DBpedia Spotlight angegeben ist und der Teil des Textes, der annotiert wurde, in diesem Fall von Zeichen 9 bis 19 reicht. Mit dem Pr\u00e4dikat hasAnnotation ist es mit dem oben angegebenen Kontext verkn\u00fcpft. Das zweite Triple verkn\u00fcpft den annotierten Text mit der spezifischen DBpedia-Entit\u00e4t \u00fcber das Pr\u00e4dikat taIndentRef . SpaCy ist ein Annotator, der linguistische Informationen in Texten identifiziert, wie z.B. die Wortart, Named Entity Recognition und morphologische Merkmale. Die aus spaCy resultierenden annotierten Texte sind mit externen linguistischen Wissensgraphen verkn\u00fcpft, wie z.B. WordNet. Die spaCy-Annotationen folgen \u00e4hnlichen Mustern wie die von DBpedia Spotlight und sehen wie folgt aus: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=spacy_p=name_char=9,19> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=spacy_p=name_char=9,19> <http://www.w3.org/2005/11/its/rdf#taIdentRef> <http://globalwordnet.org/ili/i96649> . Das Subjekt im ersten Triple gibt den Namen des Annotators als spaCy an, w\u00e4hrend das zweite Triple den annotierten Text mit der spezifischen WordNet-Entit\u00e4t (auch als Synset bezeichnet) verkn\u00fcpft. Auf \u00e4hnliche Weise wird dieser Prozess auch f\u00fcr andere Objektliterale, die mit der Subjektressource verkn\u00fcpft sind, wie description (https://schema.org/description) und keywords (https://schema.org/keywords), durchgef\u00fchrt. Im n\u00e4chsten Abschnitt werden wir die Anwendungsbereiche untersuchen, die uns durch diese Annotationen er\u00f6ffnet werden.","title":"Semantische Analyse"},{"location":"annotationen/#semantische-analyse-in-knowledge-graphs","text":"Die semantische Analyse innerhalb von Wissensgraphen, die auf RDF (Resource Description Framework) basieren, bezieht sich auf den Prozess der Interpretation und Verarbeitung von Daten, um deren Bedeutung und Beziehungen zu verstehen. Durch die Verwendung von Ontologien und Vokabularen erm\u00f6glicht die semantische Analyse, dass Informationen nicht nur als einfache Datenpunkte, sondern als bedeutungsvolle Entit\u00e4ten und deren Verkn\u00fcpfungen betrachtet werden. Dies f\u00f6rdert die F\u00e4higkeit, komplexe Abfragen zu stellen, inferenzielle Schlussfolgerungen zu ziehen und neue Erkenntnisse aus den verkn\u00fcpften Daten zu gewinnen. In Wissensgraphen wird die semantische Analyse genutzt, um die Interoperabilit\u00e4t zwischen verschiedenen Datenquellen zu verbessern und eine tiefere Einsicht in die zugrunde liegenden Informationen zu erm\u00f6glichen. Zu diesem Zweck werden Annotationen verwendet, und wir betrachten dies in den folgenden Abschnitten n\u00e4her.","title":"Semantische Analyse in Knowledge Graphs"},{"location":"annotationen/#annotationen","text":"Wie bereits erw\u00e4hnt, k\u00f6nnen RDF Daten in Form von Tripeln dargestellt werden, die aus einem Subjekt, einem Pr\u00e4dikat und einem Objekt bestehen. Das Objekt kann entweder ein Literal oder eine Ressource (IRI) sein. Ein Literal ist ein konkreter Wert, wie zum Beispiel ein Text oder eine Zahl, der direkt in den Tripel eingef\u00fcgt wird, wie \"42\" oder \"Hallo Welt\". Eine Ressource hingegen verweist auf ein Konzept oder eine Entit\u00e4t, die durch eine IRI identifiziert wird, wie zum Beispiel eine Person oder einen Ort. NIF , das f\u00fcr NLP Interchange Format steht, ist eine Architektur und Methodologie zur Annotation von Literalen oder Texten innerhalb eines Wissensgraphen. Es erm\u00f6glicht die standardisierte Darstellung von Textannotationen in RDF (Resource Description Framework), wodurch die Integration von nat\u00fcrlichen Sprachverarbeitungswerkzeugen und -ressourcen erleichtert wird. Mit NIF k\u00f6nnen verschiedene Entit\u00e4ten, Konzepte und Beziehungen innerhalb von Texten annotiert werden, was die Interoperabilit\u00e4t zwischen unterschiedlichen NLP-Systemen f\u00f6rdert. Diese Flexibilit\u00e4t und die M\u00f6glichkeit, kontextuelle Informationen einzubeziehen, machen NIF zu einem wertvollen Instrument f\u00fcr die Anreicherung von Wissensgraphen mit reichhaltigen, annotierten Textdaten. Schauen wir uns noch einmal unser Triple an, das den Titel der \"Satz des Pythagoras\" Ressource darstellt: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://schema.org/name> \"Satz des Pythagoras\" . Wenn wir nun mit einem weiteren Triple angeben m\u00f6chten, dass wir den Text \"Satz des Pythagoras\" (in anderen Worten das Objektliteral) in diesem Triple annotieren wollen, w\u00fcrde es wie folgt aussehen: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . Der letzte Teil der Objekt-URI im Triple (nif=context_p=name_char=0,19) dient als Kontextbeschreibung dessen, was wir annotieren. In diesem Fall annotieren wir die Eigenschaft name (https://schema.org/name), und char=0,19 zeigt an, dass wir alle Zeichen im Text als unseren Kontext spezifizieren. Nachdem wir den Annotation-Kontext definiert haben, wenden wir uns nun dem eigentlichen Annotierungsprozess zu. Der Annotierungsprozess analysiert die W\u00f6rter innerhalb des festgelegten Annotation-Kontexts. Dies geschieht durch den sogenannten 'Annotator'. Es k\u00f6nnen mehrere Annotatoren auf den Text angewendet werden, und je nach Annotator sind wir in der Lage, weitere Informationen aus dem Text zu extrahieren und diese wiederum mit anderen externen Wissensgraphen zu verkn\u00fcpfen. In unserem Fall verwenden wir zwei Annotatoren, n\u00e4mlich DBpedia Spotlight und spaCy . DBpedia Spotlight ist ein Tool zur automatischen Annotation von Texten, das es erm\u00f6glicht, Entit\u00e4ten aus der DBpedia-Wissensgraph in unstrukturierten Texten zu identifizieren und zu verlinken. DBpedia-Entit\u00e4ten k\u00f6nnen auch problemlos mit Wikidata-Entit\u00e4ten verkn\u00fcpft werden, einem weiteren wichtigen externen Wissensgraphen, der strukturierte Daten \u00fcber Personen, Orte und Dinge bereitstellt. Wenn wir unser Beispiel nun weiter ausbauen, sind wir in der Lage, mit zwei neuen Tripeln, DBpedia-Entit\u00e4ten auf folgende Weise mit dem bereits definierten Kontext zu verkn\u00fcpfen: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=dbpedia-spotlight_p=name_char=9,19> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=dbpedia-spotlight_p=name_char=9,19> <http://www.w3.org/2005/11/its/rdf#taIdentRef> <http://de.dbpedia.org/resource/Pythagoras> . Im letzten Teil des Subjekts des ersten Tripels sehen wir, dass der Annotator als DBpedia Spotlight angegeben ist und der Teil des Textes, der annotiert wurde, in diesem Fall von Zeichen 9 bis 19 reicht. Mit dem Pr\u00e4dikat hasAnnotation ist es mit dem oben angegebenen Kontext verkn\u00fcpft. Das zweite Triple verkn\u00fcpft den annotierten Text mit der spezifischen DBpedia-Entit\u00e4t \u00fcber das Pr\u00e4dikat taIndentRef . SpaCy ist ein Annotator, der linguistische Informationen in Texten identifiziert, wie z.B. die Wortart, Named Entity Recognition und morphologische Merkmale. Die aus spaCy resultierenden annotierten Texte sind mit externen linguistischen Wissensgraphen verkn\u00fcpft, wie z.B. WordNet. Die spaCy-Annotationen folgen \u00e4hnlichen Mustern wie die von DBpedia Spotlight und sehen wie folgt aus: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=spacy_p=name_char=9,19> <https://w3id.org/curriculum/hasAnnotationTarget> <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_nif=context_p=name_char=0,19> . <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e_a=spacy_p=name_char=9,19> <http://www.w3.org/2005/11/its/rdf#taIdentRef> <http://globalwordnet.org/ili/i96649> . Das Subjekt im ersten Triple gibt den Namen des Annotators als spaCy an, w\u00e4hrend das zweite Triple den annotierten Text mit der spezifischen WordNet-Entit\u00e4t (auch als Synset bezeichnet) verkn\u00fcpft. Auf \u00e4hnliche Weise wird dieser Prozess auch f\u00fcr andere Objektliterale, die mit der Subjektressource verkn\u00fcpft sind, wie description (https://schema.org/description) und keywords (https://schema.org/keywords), durchgef\u00fchrt. Im n\u00e4chsten Abschnitt werden wir die Anwendungsbereiche untersuchen, die uns durch diese Annotationen er\u00f6ffnet werden.","title":"Annotationen"},{"location":"anwendungen/","text":"Anwendungsbereiche Als grundlegenden ersten Schritt w\u00e4re es n\u00fctzlich, eine einfache Textabgleichsuche in unserem Wissensgraphen durchzuf\u00fchren, um Bildungsressourcen zu finden. Dazu k\u00f6nnten wir nach W\u00f6rtern in Objektliteralen suchen, die \u00fcber die Pr\u00e4dikate description und name mit den Bildungsressourcen verkn\u00fcpft sind. Probieren Sie die SPARQL-Abfrage unten aus, um nach \"Pythagoras\" in unserem Wissensgraphen zu suchen. Zeigen Sie alle Dokumente an, die das Wort \"Pythagoras\" enthalten. Recommender Wie bereits erw\u00e4hnt, erm\u00f6glicht uns der DBPedia Spotlight Annotator, Wikidata-Entit\u00e4ten in unseren Bildungsressourcen zu identifizieren. Wir k\u00f6nnen nun die Wikidata-Entit\u00e4ten nutzen, um weitere Informationen aus dem Wikidata-Wissensgraphen zu extrahieren. Jede Wikidata-Entit\u00e4t ist mit einer Liste von Kategorien verkn\u00fcpft. Zum Beispiel hat der Satz des Pythagoras die Wikidata-IRI https://www.wikidata.org/wiki/Q11518 , und die Kategorien Griechische Philosophie und Dreiecksgeometrie sind mit ihm verkn\u00fcpft. Das bedeutet, dass wir in der Lage sind, eine Liste von Wikidata-Kategorien mit jedem unserer Bildungsressourcendokumente zu verkn\u00fcpfen. Dies gibt uns wiederum die M\u00f6glichkeit, Dokumente miteinander zu vergleichen und Empfehlungen basierend auf den gemeinsamen Kategorien, die diese Dokumente miteinander teilen, auszusprechen. Sehen wir uns ein Beispiel an. Wenn wir unsere Suchanfrage, wie oben erkl\u00e4rt, verwenden, um nach Dokumenten \u00fcber den Satz des Pythagoras zu suchen, dann ist eines der Suchergebnisse \"Geometrie: Videos zu L\u00e4ngen, Fl\u00e4chen und Winkeln\" mit einer Wissensgraph-IRI von https://edu.yovisto.com/wlo/resource/74e54517-a997-40b4-8e58-1864a57b419e . Jetzt k\u00f6nnen wir diese Wissensgraph-IRI verwenden, um andere Dokumente basierend auf der Anzahl der gemeinsamen Kategorien, die sie haben, zu empfehlen. Zeigen Sie Dokumente an, die verwant sind an \" https://edu.yovisto.com/wlo/resource/74e54517-a997-40b4-8e58-1864a57b419e \" Ein weiterer Vorteil eines Wissensgraph-Ansatzes in einem Empfehlungssystem ist, dass wir nicht nur Empfehlungen aussprechen k\u00f6nnen, sondern auch erkl\u00e4ren k\u00f6nnen, warum diese Empfehlungen gegeben wurden. In der vorherigen Abfrage konnten wir eine Liste empfohlener Dokumente basierend auf der Anzahl der \u00fcberlappenden Kategorien erhalten. Jetzt k\u00f6nnen wir in einer Folgeabfrage jedes der empfohlenen Dokumente mit dem urspr\u00fcnglichen Dokument vergleichen, um eine genaue Liste der \u00fcberlappenden Kategorien f\u00fcr das spezifische empfohlene Dokument und das urspr\u00fcngliche Dokument zu erhalten. Im oben genannten Beispiel \"Geometrie: Videos zu L\u00e4ngen, Fl\u00e4chen und Winkeln\" war die erste Empfehlung \"ABSCHLUSSPR\u00dcFUNG Realschule Mathe \u2013 Geometrie\" mit einer Wissensgraph-IRI von https://edu.yovisto.com/wlo/resource/43be9071-ad66-44a6-8d35-23b6cc94fc04 . Da wir auch die IRI des urspr\u00fcnglichen Dokuments haben, k\u00f6nnen wir jetzt einen Vergleich anstellen, um genau zu verstehen, warum diese beiden Dokumente miteinander verbunden sind. Die Abfrage sieht wie folgt aus: Schlie\u00dflich ist es auch erw\u00e4hnenswert, dass Wikidata out-of-the-box Visualisierungen bietet, die leicht in eine Website eingebettet werden k\u00f6nnen. Da wir die entsprechenden Wikidata-Entit\u00e4ten, die mit unserem Wissensgraphen verkn\u00fcpft sind, haben, k\u00f6nnen wir ebenfalls von diesen Visualisierungen profitieren. Unten sind einige Beispiele: WordNet Einer der gro\u00dfen Vorteile der Verkn\u00fcpfung mit dem WordNet-Wissensgraphen ist, dass wir detailliertere Informationen \u00fcber die Konzepte erhalten, die wir in unserem Text identifizieren. Wenn unser Annotator beispielsweise das Substantiv \"Kohlenstoffdioxid\" im Text identifiziert hat, sind wir in der Lage, eine Visualisierung aus dem WordNet-Wissensgraphen zu generieren, die wie folgt aussieht: Ein weiterer Vorteil von WordNet ist der sogenannte Interlinguale Indikator (ILI), der ein Identifikator ist, der \u00e4hnliche Konzepte in verschiedenen Sprachen miteinander verkn\u00fcpft. Dies erm\u00f6glicht es uns beispielsweise, unsere Visualisierung zu erweitern, um ein besseres kontextuelles Verst\u00e4ndnis eines Konzepts in verschiedenen Sprachen zu erhalten. Unten ist eine Visualisierung des Substantiv \"Kohlenstoffdioxid\" mit dem Deutschen und dem Englischen nebeneinander:","title":"Anwendungsbereiche"},{"location":"anwendungen/#anwendungsbereiche","text":"Als grundlegenden ersten Schritt w\u00e4re es n\u00fctzlich, eine einfache Textabgleichsuche in unserem Wissensgraphen durchzuf\u00fchren, um Bildungsressourcen zu finden. Dazu k\u00f6nnten wir nach W\u00f6rtern in Objektliteralen suchen, die \u00fcber die Pr\u00e4dikate description und name mit den Bildungsressourcen verkn\u00fcpft sind. Probieren Sie die SPARQL-Abfrage unten aus, um nach \"Pythagoras\" in unserem Wissensgraphen zu suchen. Zeigen Sie alle Dokumente an, die das Wort \"Pythagoras\" enthalten.","title":"Anwendungsbereiche"},{"location":"anwendungen/#recommender","text":"Wie bereits erw\u00e4hnt, erm\u00f6glicht uns der DBPedia Spotlight Annotator, Wikidata-Entit\u00e4ten in unseren Bildungsressourcen zu identifizieren. Wir k\u00f6nnen nun die Wikidata-Entit\u00e4ten nutzen, um weitere Informationen aus dem Wikidata-Wissensgraphen zu extrahieren. Jede Wikidata-Entit\u00e4t ist mit einer Liste von Kategorien verkn\u00fcpft. Zum Beispiel hat der Satz des Pythagoras die Wikidata-IRI https://www.wikidata.org/wiki/Q11518 , und die Kategorien Griechische Philosophie und Dreiecksgeometrie sind mit ihm verkn\u00fcpft. Das bedeutet, dass wir in der Lage sind, eine Liste von Wikidata-Kategorien mit jedem unserer Bildungsressourcendokumente zu verkn\u00fcpfen. Dies gibt uns wiederum die M\u00f6glichkeit, Dokumente miteinander zu vergleichen und Empfehlungen basierend auf den gemeinsamen Kategorien, die diese Dokumente miteinander teilen, auszusprechen. Sehen wir uns ein Beispiel an. Wenn wir unsere Suchanfrage, wie oben erkl\u00e4rt, verwenden, um nach Dokumenten \u00fcber den Satz des Pythagoras zu suchen, dann ist eines der Suchergebnisse \"Geometrie: Videos zu L\u00e4ngen, Fl\u00e4chen und Winkeln\" mit einer Wissensgraph-IRI von https://edu.yovisto.com/wlo/resource/74e54517-a997-40b4-8e58-1864a57b419e . Jetzt k\u00f6nnen wir diese Wissensgraph-IRI verwenden, um andere Dokumente basierend auf der Anzahl der gemeinsamen Kategorien, die sie haben, zu empfehlen. Zeigen Sie Dokumente an, die verwant sind an \" https://edu.yovisto.com/wlo/resource/74e54517-a997-40b4-8e58-1864a57b419e \" Ein weiterer Vorteil eines Wissensgraph-Ansatzes in einem Empfehlungssystem ist, dass wir nicht nur Empfehlungen aussprechen k\u00f6nnen, sondern auch erkl\u00e4ren k\u00f6nnen, warum diese Empfehlungen gegeben wurden. In der vorherigen Abfrage konnten wir eine Liste empfohlener Dokumente basierend auf der Anzahl der \u00fcberlappenden Kategorien erhalten. Jetzt k\u00f6nnen wir in einer Folgeabfrage jedes der empfohlenen Dokumente mit dem urspr\u00fcnglichen Dokument vergleichen, um eine genaue Liste der \u00fcberlappenden Kategorien f\u00fcr das spezifische empfohlene Dokument und das urspr\u00fcngliche Dokument zu erhalten. Im oben genannten Beispiel \"Geometrie: Videos zu L\u00e4ngen, Fl\u00e4chen und Winkeln\" war die erste Empfehlung \"ABSCHLUSSPR\u00dcFUNG Realschule Mathe \u2013 Geometrie\" mit einer Wissensgraph-IRI von https://edu.yovisto.com/wlo/resource/43be9071-ad66-44a6-8d35-23b6cc94fc04 . Da wir auch die IRI des urspr\u00fcnglichen Dokuments haben, k\u00f6nnen wir jetzt einen Vergleich anstellen, um genau zu verstehen, warum diese beiden Dokumente miteinander verbunden sind. Die Abfrage sieht wie folgt aus: Schlie\u00dflich ist es auch erw\u00e4hnenswert, dass Wikidata out-of-the-box Visualisierungen bietet, die leicht in eine Website eingebettet werden k\u00f6nnen. Da wir die entsprechenden Wikidata-Entit\u00e4ten, die mit unserem Wissensgraphen verkn\u00fcpft sind, haben, k\u00f6nnen wir ebenfalls von diesen Visualisierungen profitieren. Unten sind einige Beispiele:","title":"Recommender"},{"location":"anwendungen/#wordnet","text":"Einer der gro\u00dfen Vorteile der Verkn\u00fcpfung mit dem WordNet-Wissensgraphen ist, dass wir detailliertere Informationen \u00fcber die Konzepte erhalten, die wir in unserem Text identifizieren. Wenn unser Annotator beispielsweise das Substantiv \"Kohlenstoffdioxid\" im Text identifiziert hat, sind wir in der Lage, eine Visualisierung aus dem WordNet-Wissensgraphen zu generieren, die wie folgt aussieht: Ein weiterer Vorteil von WordNet ist der sogenannte Interlinguale Indikator (ILI), der ein Identifikator ist, der \u00e4hnliche Konzepte in verschiedenen Sprachen miteinander verkn\u00fcpft. Dies erm\u00f6glicht es uns beispielsweise, unsere Visualisierung zu erweitern, um ein besseres kontextuelles Verst\u00e4ndnis eines Konzepts in verschiedenen Sprachen zu erhalten. Unten ist eine Visualisierung des Substantiv \"Kohlenstoffdioxid\" mit dem Deutschen und dem Englischen nebeneinander:","title":"WordNet"},{"location":"qualitaet/","text":"Qualit\u00e4tssicherung Obwohl die Annotatoren recht gut darin sind, Entit\u00e4ten im Text zu identifizieren, machen sie dennoch Fehler. Dies ist besonders auff\u00e4llig bei Named Entities, die mehrere Bedeutungen haben k\u00f6nnen. Zum Beispiel kann das Wort \"Churchill\" in einem Text entweder auf den britischen Politiker \"Winston Churchill\" oder auf eine kanadische Stadt namens \"Churchill\" verweisen. Gelegentlich ist der Annotator nicht in der Lage, die korrekte Entit\u00e4t aus dem Kontext abzuleiten, was zu Fehlklassifikationen f\u00fchrt. Um dieses Problem anzugehen und die Qualit\u00e4t zu verbessern, k\u00f6nnten wir mehrere Annotatoren einsetzen, die Wikidata-Entit\u00e4ten im gleichen Text klassifizieren. Gl\u00fccklicherweise ist DBPedia Spotlight nicht der einzige Annotator, der in der Lage ist, Wikidata-Entit\u00e4ten zu klassifizieren. Der yovisto-KEA-Annotator klassifiziert ebenfalls Wikidata-Entit\u00e4ten. In diesem Zusammenhang ist es wichtig, dass die Annotatoren unterschiedliche Algorithmen verwenden, wenn sie die Wikidata-Entit\u00e4ten klassifizieren, da sonst die Fehler wiederholt werden. Dies erm\u00f6glicht es uns nun zu schlie\u00dfen, dass die Genauigkeit h\u00f6her ist, wenn beide Annotatoren eine bestimmte Wikidata-Entit\u00e4t f\u00fcr denselben Textabschnitt klassifiziert haben. Wenn beide Annotatoren die Wikidata-Entit\u00e4t f\u00fcr Pythagoras im Text, der mit unserer Bildungsressource verkn\u00fcpft ist, klassifiziert haben, k\u00f6nnen wir dies in unserem Wissensgraphen wie folgt ausdr\u00fccken: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel2> <http://de.dbpedia.org/resource/Pythagoras> . In diesem Beispiel haben wir die Bildungsressource mit der Wikidata (DBpedia)-Entit\u00e4t \u00fcber ein sogenanntes Level-2-Pr\u00e4dikat verbunden. Sollte nur einer der Annotatoren eine Wikidata-Entit\u00e4t im Text klassifizieren, k\u00f6nnen wir dies dennoch in unserem Wissensgraphen mit einem Level-1-Pr\u00e4dikat wie folgt ausdr\u00fccken: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel1> <http://de.dbpedia.org/resource/Pythagoras> . Interessanterweise sind einige Wikidata-Entit\u00e4ten im Wikidata-Wissensgraphen auch \u00fcber den WordNet-ILI mit WordNet-Konzepten verkn\u00fcpft. Dies er\u00f6ffnet weitere M\u00f6glichkeiten f\u00fcr Qualit\u00e4tspr\u00fcfungen unserer Annotationen. Wenn beispielsweise einer unserer Wikidata-Annotatoren eine Wikidata-Entit\u00e4t mit einem WordNet-ILI identifiziert hat und unser spaCy-Annotator das WordNet-Konzept mit demselben WordNet-ILI identifiziert hat, das auf der Wikidata-Entit\u00e4t vorhanden ist, k\u00f6nnen wir es ebenfalls mit einem Level-2-Pr\u00e4dikat verkn\u00fcpfen. Dar\u00fcber hinaus, wenn beide Wikidata-Annotatoren (DBpedia Spotlight und yovisto-KEA) dieselbe Wikidata-Entit\u00e4t klassifiziert haben, die mit dem WordNet-Konzept verkn\u00fcpft ist, k\u00f6nnten wir die Bildungsressource mit der Wikidata-Entit\u00e4t \u00fcber ein Level-3-Pr\u00e4dikat verkn\u00fcpfen. Dies w\u00e4re auch unser h\u00f6chster best\u00e4tigter Qualit\u00e4tsindikator und kann in unserem Wissensgraphen wie folgt ausgedr\u00fcckt werden: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel3> <http://de.dbpedia.org/resource/Pythagoras> . Derzeit haben etwa 9300 Wikidata-Entit\u00e4ten Verkn\u00fcpfungen zu WordNet-Konzepten \u00fcber den ILI, aber dies ist ein Forschungsfeld, das kontinuierlich weiterentwickelt wird, mit der klaren M\u00f6glichkeit, dies in naher Zukunft auf etwa 30000 zu erweitern. Dies k\u00f6nnte auch einen erheblichen Einfluss auf die Qualit\u00e4t der Annotationen in unserem Wissensgraphen haben. Der folgende Graph zeigt die Anzahl der \u00fcberlappenden \u00dcbereinstimmungen f\u00fcr jeden Annotator in Bezug auf die oben genannten Annotationslevel. Wie erw\u00e4hnt, wird die Anzahl der \u00fcberlappenden WordNet-Annotationen mit anderen Annotatoren voraussichtlich stark steigen, angesichts der zunehmenden Verkn\u00fcpfungen zwischen Wikidata und WordNet.","title":"Qualit\u00e4tssicherung"},{"location":"qualitaet/#qualitatssicherung","text":"Obwohl die Annotatoren recht gut darin sind, Entit\u00e4ten im Text zu identifizieren, machen sie dennoch Fehler. Dies ist besonders auff\u00e4llig bei Named Entities, die mehrere Bedeutungen haben k\u00f6nnen. Zum Beispiel kann das Wort \"Churchill\" in einem Text entweder auf den britischen Politiker \"Winston Churchill\" oder auf eine kanadische Stadt namens \"Churchill\" verweisen. Gelegentlich ist der Annotator nicht in der Lage, die korrekte Entit\u00e4t aus dem Kontext abzuleiten, was zu Fehlklassifikationen f\u00fchrt. Um dieses Problem anzugehen und die Qualit\u00e4t zu verbessern, k\u00f6nnten wir mehrere Annotatoren einsetzen, die Wikidata-Entit\u00e4ten im gleichen Text klassifizieren. Gl\u00fccklicherweise ist DBPedia Spotlight nicht der einzige Annotator, der in der Lage ist, Wikidata-Entit\u00e4ten zu klassifizieren. Der yovisto-KEA-Annotator klassifiziert ebenfalls Wikidata-Entit\u00e4ten. In diesem Zusammenhang ist es wichtig, dass die Annotatoren unterschiedliche Algorithmen verwenden, wenn sie die Wikidata-Entit\u00e4ten klassifizieren, da sonst die Fehler wiederholt werden. Dies erm\u00f6glicht es uns nun zu schlie\u00dfen, dass die Genauigkeit h\u00f6her ist, wenn beide Annotatoren eine bestimmte Wikidata-Entit\u00e4t f\u00fcr denselben Textabschnitt klassifiziert haben. Wenn beide Annotatoren die Wikidata-Entit\u00e4t f\u00fcr Pythagoras im Text, der mit unserer Bildungsressource verkn\u00fcpft ist, klassifiziert haben, k\u00f6nnen wir dies in unserem Wissensgraphen wie folgt ausdr\u00fccken: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel2> <http://de.dbpedia.org/resource/Pythagoras> . In diesem Beispiel haben wir die Bildungsressource mit der Wikidata (DBpedia)-Entit\u00e4t \u00fcber ein sogenanntes Level-2-Pr\u00e4dikat verbunden. Sollte nur einer der Annotatoren eine Wikidata-Entit\u00e4t im Text klassifizieren, k\u00f6nnen wir dies dennoch in unserem Wissensgraphen mit einem Level-1-Pr\u00e4dikat wie folgt ausdr\u00fccken: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel1> <http://de.dbpedia.org/resource/Pythagoras> . Interessanterweise sind einige Wikidata-Entit\u00e4ten im Wikidata-Wissensgraphen auch \u00fcber den WordNet-ILI mit WordNet-Konzepten verkn\u00fcpft. Dies er\u00f6ffnet weitere M\u00f6glichkeiten f\u00fcr Qualit\u00e4tspr\u00fcfungen unserer Annotationen. Wenn beispielsweise einer unserer Wikidata-Annotatoren eine Wikidata-Entit\u00e4t mit einem WordNet-ILI identifiziert hat und unser spaCy-Annotator das WordNet-Konzept mit demselben WordNet-ILI identifiziert hat, das auf der Wikidata-Entit\u00e4t vorhanden ist, k\u00f6nnen wir es ebenfalls mit einem Level-2-Pr\u00e4dikat verkn\u00fcpfen. Dar\u00fcber hinaus, wenn beide Wikidata-Annotatoren (DBpedia Spotlight und yovisto-KEA) dieselbe Wikidata-Entit\u00e4t klassifiziert haben, die mit dem WordNet-Konzept verkn\u00fcpft ist, k\u00f6nnten wir die Bildungsressource mit der Wikidata-Entit\u00e4t \u00fcber ein Level-3-Pr\u00e4dikat verkn\u00fcpfen. Dies w\u00e4re auch unser h\u00f6chster best\u00e4tigter Qualit\u00e4tsindikator und kann in unserem Wissensgraphen wie folgt ausgedr\u00fcckt werden: <https://edu.yovisto.com/wlo/resource/a44c7b05-2a37-455f-a743-312ff064102e> <http://edu.yovisto.com/ontology/1.0/annotationLevel3> <http://de.dbpedia.org/resource/Pythagoras> . Derzeit haben etwa 9300 Wikidata-Entit\u00e4ten Verkn\u00fcpfungen zu WordNet-Konzepten \u00fcber den ILI, aber dies ist ein Forschungsfeld, das kontinuierlich weiterentwickelt wird, mit der klaren M\u00f6glichkeit, dies in naher Zukunft auf etwa 30000 zu erweitern. Dies k\u00f6nnte auch einen erheblichen Einfluss auf die Qualit\u00e4t der Annotationen in unserem Wissensgraphen haben. Der folgende Graph zeigt die Anzahl der \u00fcberlappenden \u00dcbereinstimmungen f\u00fcr jeden Annotator in Bezug auf die oben genannten Annotationslevel. Wie erw\u00e4hnt, wird die Anzahl der \u00fcberlappenden WordNet-Annotationen mit anderen Annotatoren voraussichtlich stark steigen, angesichts der zunehmenden Verkn\u00fcpfungen zwischen Wikidata und WordNet.","title":"Qualit\u00e4tssicherung"}]}